# ğŸŒŸ **Fine-Tune Phi-2 with QLoRA!** ğŸŒŸ

Welcome to **Fine-Tune Phi-2 with QLoRA**, an innovative project that demonstrates how to fine-tune the lightweight **microsoft/phi-2** language model using **QLoRA (Quantized Low-Rank Adaptation)** on a single text document! This repository showcases an efficient fine-tuning pipeline designed for resource-constrained environments, leveraging **4-bit quantization**, **LoRA**, and **PyTorch** to adapt the model to specific data (e.g., bio.txt). Perfect for developers, researchers, or AI enthusiasts looking to customize open-source LLMs with minimal hardware requirements! ğŸš€

ğŸ”— **Repository Name**: Fine-Tune Phi-2 with QLoRA  
ğŸ“… **Last Updated**: June 2025  
ğŸ‘¨â€ğŸ’» **Author**: Muhammad Ahmad Nadeem

* * *

ğŸš€ Key Features
---------------

*   **Efficient Fine-Tuning** âš¡: Uses QLoRA to fine-tune phi-2 with 4-bit quantization, reducing memory usage.
*   **Customizable Pipeline** ğŸ›ï¸: Easily adapt the model to any text document by modifying the input file.
*   **GPU Optimization** ğŸ’»: Leverages CUDA for speed (falls back to CPU if unavailable).
*   **Open-Source Tools** ğŸŒ: Built with HuggingFace Transformers, Datasets, and PEFT for accessibility.
*   **Interactive Output** ğŸ’¬: Generates text responses post-training, like answering "Who is Bruce Wayne?".

* * *

ğŸ› ï¸ Tech Stack
--------------

Hereâ€™s the toolkit powering this project!

ğŸ›¡ï¸ Python

![Generated Image](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python)

  
ğŸ›¡ï¸ PyTorch

![Generated Image](https://img.shields.io/badge/PyTorch-2.0%2B-orange?logo=pytorch)

  
ğŸ›¡ï¸ HuggingFace Transformers

![Generated Image](https://img.shields.io/badge/HuggingFace-Transformers-yellow?logo=huggingface)

  
ğŸ›¡ï¸ Datasets

![Generated Image](https://img.shields.io/badge/Datasets-2.0%2B-green?logo=huggingface)

  
ğŸ›¡ï¸ BitsAndBytes

![Generated Image](https://img.shields.io/badge/BitsAndBytes-4bit-purple)

  
ğŸ›¡ï¸ PEFT

![Generated Image](https://img.shields.io/badge/PEFT-QLoRA-blueviolet)

  
ğŸ›¡ï¸ PyMuPDF

![Generated Image](https://img.shields.io/badge/PyMuPDF-Text%20Extraction-red)

* * *

ğŸ“‚ Project Structure
--------------------

This repository contains a single Jupyter notebook:

*   **fine-tune.ipynb**: The main Colab notebook with the complete fine-tuning pipeline, including installation, data processing, model training, and inference.

* * *

ğŸ–¥ï¸ How to Get Started
----------------------

Follow these steps to run the project! ğŸš€

### Prerequisites

*   A Google Colab account with GPU access (recommended) ğŸŒ
*   Basic knowledge of Python and Jupyter notebooks ğŸ““

### Step 1: Open in Google Colab

Click this link to open the notebook in Colab: [Colab](https://colab.research.google.com/drive/1RsXFmlxfhfjsgLk9t4oLxJDKR6r982MH)

### Step 2: Upload Your Document

Replace the default **/content/bio.txt** with your own text file by uploading it to the Colab environment.

### Step 3: Install Dependencies

The notebook automatically installs required packages (e.g., pymupdf, transformers, datasets) when you run the first cell.

### Step 4: Run the Notebook

Execute each cell sequentially:

1.  Install dependencies.
2.  Load and process the text data.
3.  Fine-tune the phi-2 model with QLoRA.
4.  Save the trained model and test it with a sample query!

### Step 5: Test the Model

After training, use the pipeline to generate text (e.g., "Who is Bruce Wayne?") and explore the results!

* * *

ğŸ“Š How It Works
---------------

1.  **Text Extraction** ğŸ“œ: Extracts text from **bio.txt** using PyMuPDF.
2.  **Chunking** âœ‚ï¸: Splits the text into 300-word chunks for processing.
3.  **Tokenization** ğŸ”¢: Prepares data with HuggingFaceâ€™s AutoTokenizer.
4.  **QLoRA Fine-Tuning** ğŸ¤–: Applies 4-bit quantization and LoRA to fine-tune phi-2 efficiently.
5.  **Training** ğŸ¯: Trains the model for 3 epochs using the Trainer API.
6.  **Inference** ğŸ’¬: Generates responses using the fine-tuned model via a pipeline.

* * *

ğŸ§  Why This Project Stands Out
------------------------------

*   **Low-Resource Friendly** ğŸŒ±: Fine-tunes a large model on minimal hardware thanks to QLoRA.
*   **Practical Application** ğŸ› ï¸: Demonstrates real-world use with customizable text data.
*   **Colab-Ready** ğŸŒ: Seamlessly runs on Google Colab with free GPU support.
*   **Educational Value** ğŸ“š: Perfect for learning fine-tuning techniques and model optimization.

* * *

ğŸ¤ Contributing
---------------

Love the project? Contribute! ğŸ´

1.  Fork the repository.
2.  Create a branch (git checkout -b feature/new-feature).
3.  Commit changes (git commit -m "Add new feature").
4.  Push and open a Pull Request ğŸ“¬.  
    Suggestions or bugs? Open an issue! ğŸ¤—

* * *

ğŸ“œ License
----------

Licensed under the Apache License. See the LICENSE file for details.

* * *

ğŸ™Œ Acknowledgments
------------------

*   **HuggingFace** for Transformers and Datasets.
*   **Microsoft** for the phi-2 model.
*   **PyMuPDF** for text extraction.
*   **Google Colab** for free GPU access.

* * *

ğŸ‰ **Thank you for exploring Fine-Tune Phi-2 with QLoRA!** Dive in and unleash the power of fine-tuned LLMs! ğŸ’»